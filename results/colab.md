# Example results on Google Colab

[Results are as reported by this notebook](/results/pyhpc-benchmarks-colab.ipynb).
To re-run these experiments, [just head over to Google Colab](https://colab.research.google.com/), upload the notebook, and run the cells one by one.

Hardware at the time of writing (19 Dec 2019):
- Intel(R) Xeon(R) CPU @ 2.30GHz (1 core, 2 threads)
- 12.6GB of RAM
- NVidia Tesla K80 GPU with 12GB memory

**Caveat**: 
Jax does not support 64bit floating point precision on TPU architectures (yet). 
Therefore, the Jax + TPU results are not bit-identical to all other backends and devices, so it's not really an apples-to-apples comparison.

**Caveat$^2$**:
I didn't manage to get Bohrium to work on Colab, so it's missing from these results.

## Contents

- [Example results on Google Colab](#example-results-on-google-colab)
  - [Contents](#contents)
  - [Equation of state](#equation-of-state)
    - [CPU](#cpu)
    - [GPU](#gpu)
    - [TPU](#tpu)
  - [Isoneutral mixing](#isoneutral-mixing)
    - [CPU](#cpu-1)
    - [GPU](#gpu-1)
    - [TPU](#tpu-1)
  - [Turbulent kinetic energy](#turbulent-kinetic-energy)
    - [CPU](#cpu-2)
    - [GPU](#gpu-2)
    - [TPU](#tpu-2)

## Equation of state

An equation consisting of >100 terms with no data dependencies and only elementary math. This benchmark should represent a best-case scenario for vector instructions and GPU performance.

### CPU

```bash
$ taskset -c 0 python run.py benchmarks/equation_of_state/

Estimating repetitions...
Running 100116 benchmarks...  [####################################]  100%          

benchmarks.equation_of_state
============================
Running on CPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  numba         10,000     0.000     0.000     0.000     0.000     0.000     0.000     0.006     2.994
       4,096  jax           10,000     0.000     0.000     0.000     0.000     0.000     0.000     0.004     2.744
       4,096  theano        10,000     0.001     0.000     0.000     0.001     0.001     0.001     0.006     2.065
       4,096  numpy         10,000     0.001     0.000     0.001     0.001     0.001     0.001     0.008     1.000
       4,096  tensorflow    10,000     0.002     0.000     0.001     0.002     0.002     0.002     0.008     0.702
       4,096  pytorch       10,000     0.002     0.000     0.001     0.002     0.002     0.002     0.010     0.667

      16,384  jax           10,000     0.001     0.000     0.001     0.001     0.001     0.001     0.005     3.880
      16,384  numba         10,000     0.002     0.000     0.001     0.002     0.002     0.002     0.008     3.097
      16,384  theano        10,000     0.002     0.000     0.002     0.002     0.002     0.002     0.009     2.360
      16,384  pytorch        1,000     0.005     0.001     0.004     0.005     0.005     0.005     0.011     1.057
      16,384  numpy          1,000     0.005     0.001     0.004     0.005     0.005     0.006     0.012     1.000
      16,384  tensorflow     1,000     0.006     0.001     0.005     0.006     0.006     0.006     0.014     0.887

      65,536  jax            1,000     0.004     0.001     0.004     0.004     0.004     0.004     0.009    38.725
      65,536  numba          1,000     0.007     0.001     0.006     0.006     0.007     0.007     0.013    25.244
      65,536  theano         1,000     0.009     0.001     0.008     0.008     0.008     0.009     0.015    19.593
      65,536  tensorflow       100     0.054     0.006     0.032     0.053     0.056     0.058     0.066     3.132
      65,536  pytorch          100     0.094     0.006     0.066     0.092     0.094     0.097     0.108     1.798
      65,536  numpy            100     0.170     0.006     0.148     0.167     0.169     0.172     0.191     1.000

     262,144  jax            1,000     0.016     0.002     0.013     0.016     0.017     0.017     0.024    15.952
     262,144  numba          1,000     0.025     0.001     0.023     0.024     0.024     0.024     0.036    10.682
     262,144  theano         1,000     0.031     0.002     0.028     0.030     0.030     0.031     0.044     8.539
     262,144  tensorflow       100     0.128     0.003     0.124     0.125     0.127     0.129     0.137     2.054
     262,144  pytorch          100     0.225     0.006     0.205     0.222     0.225     0.229     0.242     1.165
     262,144  numpy            100     0.263     0.009     0.233     0.260     0.263     0.266     0.282     1.000

   1,048,576  jax              100     0.062     0.003     0.060     0.060     0.061     0.064     0.075    10.496
   1,048,576  numba            100     0.100     0.004     0.096     0.097     0.099     0.101     0.118     6.582
   1,048,576  theano           100     0.128     0.006     0.122     0.124     0.127     0.130     0.153     5.119
   1,048,576  tensorflow        10     0.512     0.009     0.502     0.506     0.510     0.515     0.535     1.280
   1,048,576  numpy             10     0.655     0.005     0.648     0.653     0.656     0.659     0.663     1.000
   1,048,576  pytorch           10     0.704     0.008     0.695     0.697     0.703     0.708     0.720     0.930

   4,194,304  jax              100     0.231     0.005     0.223     0.226     0.231     0.234     0.245    10.442
   4,194,304  numba             10     0.382     0.004     0.378     0.379     0.380     0.383     0.390     6.317
   4,194,304  theano            10     0.498     0.008     0.485     0.494     0.496     0.500     0.513     4.838
   4,194,304  tensorflow        10     2.131     0.013     2.098     2.125     2.134     2.141     2.145     1.131
   4,194,304  numpy             10     2.411     0.009     2.392     2.404     2.413     2.417     2.424     1.000
   4,194,304  pytorch           10     2.684     0.005     2.677     2.680     2.685     2.688     2.695     0.898

(time in wall seconds, less is better)
```

### GPU

```bash
$ for backend in jax tensorflow pytorch cupy; do CUDA_VISIBLE_DEVICES="0" python run.py benchmarks/equation_of_state/ --device gpu -b $backend -b numpy; done

Estimating repetitions...
Running 152232 benchmarks...  [####################################]  100%          

benchmarks.equation_of_state
============================
Running on GPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  jax           10,000     0.000     0.000     0.000     0.000     0.000     0.000     0.007     5.390
       4,096  numpy         10,000     0.002     0.000     0.001     0.002     0.002     0.002     0.008     1.000

      16,384  jax          100,000     0.000     0.000     0.000     0.000     0.000     0.000     0.019    25.672
      16,384  numpy          1,000     0.009     0.001     0.007     0.008     0.009     0.009     0.018     1.000

      65,536  jax           10,000     0.000     0.000     0.000     0.000     0.000     0.001     0.010   145.566
      65,536  numpy            100     0.073     0.066     0.047     0.049     0.051     0.052     0.286     1.000

     262,144  jax           10,000     0.001     0.002     0.000     0.001     0.001     0.001     0.014   295.936
     262,144  numpy            100     0.390     0.020     0.351     0.375     0.390     0.402     0.471     1.000

   1,048,576  jax           10,000     0.002     0.002     0.001     0.002     0.002     0.002     0.013   429.396
   1,048,576  numpy             10     0.965     0.021     0.927     0.953     0.964     0.984     0.993     1.000

   4,194,304  jax            1,000     0.007     0.001     0.006     0.006     0.008     0.008     0.012   462.141
   4,194,304  numpy             10     3.356     0.024     3.319     3.338     3.351     3.367     3.405     1.000

(time in wall seconds, less is better)

Estimating repetitions...
Running 33432 benchmarks...  [####################################]  100%          

benchmarks.equation_of_state
============================
Running on GPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  numpy         10,000     0.002     0.000     0.001     0.002     0.002     0.002     0.007     1.000
       4,096  tensorflow    10,000     0.004     0.012     0.002     0.003     0.003     0.003     0.197     0.373

      16,384  tensorflow    10,000     0.005     0.013     0.002     0.003     0.003     0.003     0.205     1.854
      16,384  numpy          1,000     0.008     0.001     0.007     0.008     0.008     0.009     0.015     1.000

      65,536  tensorflow     1,000     0.005     0.015     0.003     0.003     0.003     0.003     0.193     9.948
      65,536  numpy            100     0.052     0.003     0.047     0.050     0.051     0.053     0.063     1.000

     262,144  tensorflow     1,000     0.005     0.013     0.003     0.003     0.004     0.004     0.188    66.576
     262,144  numpy            100     0.324     0.041     0.213     0.322     0.331     0.340     0.447     1.000

   1,048,576  tensorflow       100     0.005     0.001     0.005     0.005     0.005     0.006     0.009   165.565
   1,048,576  numpy             10     0.901     0.036     0.850     0.883     0.895     0.908     0.995     1.000

   4,194,304  tensorflow       100     0.015     0.009     0.012     0.013     0.013     0.014     0.108   225.709
   4,194,304  numpy             10     3.282     0.047     3.183     3.264     3.279     3.299     3.379     1.000

(time in wall seconds, less is better)

Estimating repetitions...
Running 332232 benchmarks...  [####################################]  100%          

benchmarks.equation_of_state
============================
Running on GPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  pytorch      100,000     0.000     0.000     0.000     0.000     0.000     0.000     0.008    20.772
       4,096  numpy         10,000     0.002     0.000     0.001     0.002     0.002     0.002     0.012     1.000

      16,384  pytorch      100,000     0.000     0.000     0.000     0.000     0.000     0.000     0.009    68.415
      16,384  numpy          1,000     0.009     0.001     0.007     0.008     0.009     0.009     0.015     1.000

      65,536  pytorch      100,000     0.000     0.000     0.000     0.000     0.000     0.000     0.009  1050.591
      65,536  numpy            100     0.303     0.076     0.100     0.266     0.298     0.337     0.523     1.000

     262,144  pytorch       10,000     0.001     0.000     0.000     0.001     0.001     0.001     0.006   602.465
     262,144  numpy            100     0.431     0.078     0.197     0.389     0.433     0.473     0.710     1.000

   1,048,576  pytorch       10,000     0.003     0.000     0.002     0.003     0.003     0.003     0.010   406.116
   1,048,576  numpy             10     1.045     0.036     0.979     1.016     1.052     1.069     1.091     1.000

   4,194,304  pytorch        1,000     0.010     0.000     0.006     0.010     0.010     0.010     0.012   354.831
   4,194,304  numpy             10     3.438     0.038     3.398     3.404     3.420     3.467     3.508     1.000

(time in wall seconds, less is better)

Estimating repetitions...
Running 15432 benchmarks...  [####################################]  100%          

benchmarks.equation_of_state
============================
Running on GPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  numpy         10,000     0.002     0.000     0.001     0.002     0.002     0.002     0.008     1.000
       4,096  cupy           1,000     0.012     0.002     0.010     0.011     0.011     0.012     0.026     0.146

      16,384  numpy          1,000     0.008     0.001     0.007     0.008     0.008     0.009     0.016     1.000
      16,384  cupy           1,000     0.012     0.002     0.010     0.011     0.011     0.012     0.024     0.693

      65,536  cupy           1,000     0.012     0.002     0.010     0.011     0.011     0.012     0.023    12.879
      65,536  numpy            100     0.155     0.020     0.076     0.152     0.156     0.160     0.228     1.000

     262,144  cupy           1,000     0.016     0.001     0.015     0.015     0.015     0.016     0.028    17.177
     262,144  numpy            100     0.267     0.011     0.247     0.261     0.266     0.272     0.309     1.000

   1,048,576  cupy             100     0.054     0.001     0.053     0.053     0.053     0.053     0.060    15.270
   1,048,576  numpy             10     0.820     0.017     0.797     0.808     0.815     0.825     0.855     1.000

   4,194,304  cupy             100     0.204     0.005     0.203     0.203     0.203     0.203     0.238    15.491
   4,194,304  numpy             10     3.164     0.074     3.032     3.140     3.175     3.226     3.253     1.000

(time in wall seconds, less is better)
```

### TPU

```bash
$ JAX_BACKEND_TARGET="grpc://$COLAB_TPU_ADDR" python run.py benchmarks/equation_of_state -b jax -b numpy --device tpu

benchmarks.equation_of_state
============================
Running on TPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  jax           10,000     0.002     0.001     0.001     0.002     0.002     0.002     0.024     1.694
       4,096  numpy         10,000     0.004     0.001     0.002     0.003     0.004     0.004     0.016     1.000

      16,384  jax           10,000     0.002     0.001     0.001     0.002     0.002     0.002     0.012     6.065
      16,384  numpy          1,000     0.013     0.002     0.008     0.012     0.013     0.014     0.032     1.000

      65,536  jax           10,000     0.002     0.001     0.001     0.002     0.002     0.002     0.017    42.891
      65,536  numpy            100     0.095     0.014     0.063     0.091     0.095     0.103     0.150     1.000

     262,144  jax           10,000     0.002     0.001     0.001     0.002     0.002     0.003     0.018   170.553
     262,144  numpy            100     0.419     0.050     0.302     0.382     0.425     0.453     0.532     1.000

   1,048,576  jax           10,000     0.009     0.001     0.003     0.008     0.009     0.010     0.019   124.731
   1,048,576  numpy             10     1.129     0.085     0.922     1.106     1.157     1.180     1.211     1.000

   4,194,304  jax            1,000     0.047     0.008     0.029     0.038     0.047     0.054     0.065    79.958
   4,194,304  numpy             10     3.724     0.256     3.255     3.675     3.786     3.903     4.068     1.000

(time in wall seconds, less is better)
```

## Isoneutral mixing

A more balanced routine with many data dependencies (stencil operations), and tensor shapes of up to 5 dimensions. This is the most expensive part of Veros, so in a way this is the benchmark that interests me the most.

### CPU

```bash
$ taskset -c 0 python run.py benchmarks/isoneutral_mixing/

Estimating repetitions...
Running 46680 benchmarks...  [####################################]  100%          

benchmarks.isoneutral_mixing
============================
Running on CPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  numba         10,000     0.001     0.001     0.001     0.001     0.001     0.001     0.062     2.510
       4,096  jax           10,000     0.002     0.001     0.001     0.001     0.001     0.002     0.064     1.928
       4,096  theano        10,000     0.003     0.000     0.002     0.002     0.002     0.003     0.018     1.154
       4,096  numpy         10,000     0.003     0.001     0.003     0.003     0.003     0.003     0.086     1.000
       4,096  pytorch        1,000     0.006     0.002     0.005     0.005     0.005     0.006     0.065     0.521

      16,384  numba          1,000     0.006     0.001     0.005     0.005     0.005     0.006     0.018     1.947
      16,384  jax            1,000     0.006     0.001     0.005     0.006     0.006     0.006     0.018     1.781
      16,384  theano           100     0.011     0.001     0.010     0.010     0.010     0.011     0.015     1.020
      16,384  numpy          1,000     0.011     0.001     0.010     0.011     0.011     0.011     0.024     1.000
      16,384  pytorch        1,000     0.013     0.002     0.011     0.012     0.012     0.013     0.073     0.858

      65,536  numba            100     0.025     0.001     0.024     0.024     0.025     0.025     0.030     2.290
      65,536  jax            1,000     0.026     0.002     0.024     0.025     0.025     0.026     0.053     2.219
      65,536  theano           100     0.048     0.001     0.047     0.047     0.048     0.049     0.054     1.184
      65,536  numpy             10     0.057     0.002     0.056     0.056     0.056     0.059     0.061     1.000
      65,536  pytorch           10     0.058     0.002     0.056     0.057     0.058     0.059     0.063     0.986

     262,144  numba            100     0.097     0.003     0.094     0.095     0.096     0.099     0.108     2.270
     262,144  jax              100     0.104     0.006     0.100     0.101     0.103     0.105     0.158     2.123
     262,144  theano            10     0.186     0.004     0.182     0.183     0.184     0.186     0.196     1.190
     262,144  pytorch           10     0.215     0.003     0.211     0.213     0.217     0.217     0.220     1.026
     262,144  numpy             10     0.221     0.003     0.217     0.219     0.221     0.222     0.228     1.000

   1,048,576  numba             10     0.409     0.007     0.402     0.403     0.409     0.414     0.420     2.434
   1,048,576  jax               10     0.478     0.007     0.469     0.471     0.478     0.481     0.491     2.085
   1,048,576  theano            10     0.821     0.003     0.816     0.821     0.821     0.823     0.824     1.213
   1,048,576  pytorch           10     0.903     0.009     0.888     0.897     0.903     0.910     0.919     1.103
   1,048,576  numpy             10     0.996     0.007     0.987     0.992     0.995     0.999     1.013     1.000

   4,194,304  numba             10     1.663     0.016     1.641     1.654     1.658     1.671     1.697     2.806
   4,194,304  jax               10     1.962     0.012     1.941     1.955     1.961     1.971     1.984     2.378
   4,194,304  theano            10     3.493     0.033     3.454     3.472     3.485     3.497     3.572     1.336
   4,194,304  pytorch           10     4.134     0.017     4.111     4.117     4.135     4.147     4.162     1.129
   4,194,304  numpy             10     4.666     0.023     4.644     4.649     4.659     4.669     4.711     1.000

(time in wall seconds, less is better)
```

### GPU

```bash
$ for backend in jax pytorch cupy; do CUDA_VISIBLE_DEVICES="0" python run.py benchmarks/isoneutral_mixing/ --device gpu -b $backend -b numpy; done

Estimating repetitions...
Running 24432 benchmarks...  [####################################]  100%          

benchmarks.isoneutral_mixing
============================
Running on GPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  jax           10,000     0.002     0.000     0.002     0.002     0.002     0.002     0.010     2.001
       4,096  numpy          1,000     0.004     0.001     0.004     0.004     0.004     0.004     0.011     1.000

      16,384  jax           10,000     0.002     0.000     0.002     0.002     0.002     0.003     0.018     6.664
      16,384  numpy          1,000     0.016     0.001     0.015     0.016     0.016     0.017     0.040     1.000

      65,536  jax            1,000     0.005     0.001     0.005     0.005     0.005     0.005     0.014    15.516
      65,536  numpy            100     0.082     0.004     0.070     0.079     0.081     0.085     0.096     1.000

     262,144  jax            1,000     0.017     0.001     0.016     0.016     0.016     0.016     0.026    21.338
     262,144  numpy            100     0.353     0.017     0.299     0.344     0.351     0.361     0.400     1.000

   1,048,576  jax              100     0.064     0.004     0.062     0.062     0.062     0.062     0.075    20.564
   1,048,576  numpy             10     1.318     0.028     1.249     1.311     1.317     1.341     1.352     1.000

   4,194,304  jax              100     0.246     0.007     0.242     0.243     0.243     0.243     0.271    20.513
   4,194,304  numpy             10     5.038     0.075     4.879     5.011     5.059     5.076     5.159     1.000

(time in wall seconds, less is better)
Estimating repetitions...
Running 6432 benchmarks...  [####################################]  100%          

benchmarks.isoneutral_mixing
============================
Running on GPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  numpy          1,000     0.004     0.001     0.004     0.004     0.004     0.004     0.013     1.000
       4,096  pytorch        1,000     0.010     0.002     0.008     0.009     0.009     0.010     0.023     0.445

      16,384  pytorch        1,000     0.010     0.002     0.008     0.009     0.009     0.010     0.022     1.607
      16,384  numpy          1,000     0.016     0.001     0.014     0.015     0.016     0.016     0.025     1.000

      65,536  pytorch        1,000     0.010     0.002     0.009     0.009     0.010     0.011     0.022     7.021
      65,536  numpy            100     0.073     0.004     0.065     0.069     0.072     0.075     0.086     1.000

     262,144  pytorch        1,000     0.019     0.001     0.018     0.018     0.019     0.019     0.028    17.684
     262,144  numpy            100     0.339     0.031     0.260     0.322     0.332     0.346     0.417     1.000

   1,048,576  pytorch          100     0.067     0.003     0.066     0.066     0.066     0.066     0.080    19.611
   1,048,576  numpy             10     1.319     0.047     1.266     1.284     1.307     1.339     1.425     1.000

   4,194,304  pytorch          100     0.257     0.005     0.255     0.255     0.255     0.256     0.281    19.319
   4,194,304  numpy             10     4.967     0.078     4.808     4.961     4.975     4.997     5.099     1.000

(time in wall seconds, less is better)
Estimating repetitions...
Running 6342 benchmarks...  [####################################]  100%          

benchmarks.isoneutral_mixing
============================
Running on GPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  numpy          1,000     0.005     0.002     0.004     0.004     0.004     0.005     0.036     1.000
       4,096  cupy           1,000     0.017     0.003     0.014     0.016     0.016     0.018     0.033     0.293

      16,384  numpy          1,000     0.017     0.002     0.015     0.016     0.017     0.017     0.031     1.000
      16,384  cupy           1,000     0.017     0.003     0.015     0.016     0.016     0.018     0.032     0.977

      65,536  cupy           1,000     0.018     0.003     0.015     0.016     0.017     0.018     0.037     7.425
      65,536  numpy            100     0.131     0.031     0.069     0.123     0.140     0.149     0.227     1.000

     262,144  cupy           1,000     0.021     0.002     0.019     0.019     0.019     0.022     0.039    18.760
     262,144  numpy             10     0.385     0.074     0.325     0.356     0.365     0.376     0.603     1.000

   1,048,576  cupy             100     0.072     0.006     0.069     0.069     0.069     0.072     0.098    18.420
   1,048,576  numpy             10     1.332     0.068     1.207     1.311     1.322     1.328     1.489     1.000

   4,194,304  cupy             100     0.276     0.013     0.268     0.268     0.268     0.277     0.322    20.978
   4,194,304  numpy             10     5.781     0.166     5.476     5.715     5.863     5.885     5.920     1.000

(time in wall seconds, less is better)
```

### TPU

```bash
$ JAX_BACKEND_TARGET="grpc://$COLAB_TPU_ADDR" python run.py benchmarks/isoneutral_mixing -b jax -b numpy --device tpu

benchmarks.isoneutral_mixing
============================
Running on TPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  jax           10,000     0.005     0.003     0.002     0.004     0.004     0.005     0.041     1.933
       4,096  numpy          1,000     0.009     0.001     0.005     0.008     0.009     0.010     0.020     1.000

      16,384  jax           10,000     0.005     0.003     0.003     0.004     0.004     0.005     0.040     6.148
      16,384  numpy          1,000     0.030     0.004     0.021     0.028     0.030     0.032     0.055     1.000

      65,536  jax            1,000     0.017     0.006     0.006     0.012     0.016     0.021     0.051     7.817
      65,536  numpy            100     0.131     0.016     0.096     0.125     0.132     0.139     0.166     1.000

     262,144  jax            1,000     0.014     0.004     0.007     0.011     0.015     0.017     0.040    29.070
     262,144  numpy             10     0.419     0.053     0.354     0.357     0.441     0.461     0.493     1.000

   1,048,576  jax            1,000     0.063     0.007     0.047     0.058     0.061     0.065     0.106    27.709
   1,048,576  numpy             10     1.739     0.221     1.493     1.529     1.715     1.928     2.037     1.000

   4,194,304  jax              100     0.248     0.017     0.223     0.235     0.243     0.261     0.288    26.421
   4,194,304  numpy             10     6.541     0.493     5.874     6.170     6.413     6.752     7.428     1.000

(time in wall seconds, less is better)
```

## Turbulent kinetic energy

This routine consists of some stencil operations and some linear algebra (a tridiagonal matrix solver), which cannot be vectorized.

### CPU

```bash
$ taskset -c 0 python run.py benchmarks/turbulent_kinetic_energy/

Estimating repetitions...
Running 53658 benchmarks...  [####################################]  100%          

benchmarks.turbulent_kinetic_energy
===================================
Running on CPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  jax           10,000     0.001     0.000     0.001     0.001     0.001     0.001     0.019     2.414
       4,096  numba         10,000     0.001     0.000     0.001     0.001     0.001     0.001     0.020     1.972
       4,096  numpy         10,000     0.002     0.001     0.002     0.002     0.002     0.002     0.019     1.000

      16,384  jax           10,000     0.002     0.000     0.002     0.002     0.002     0.002     0.021     2.729
      16,384  numba         10,000     0.003     0.001     0.003     0.003     0.003     0.003     0.021     1.914
      16,384  numpy          1,000     0.006     0.001     0.005     0.006     0.006     0.006     0.009     1.000

      65,536  jax            1,000     0.010     0.001     0.009     0.010     0.010     0.010     0.028     2.981
      65,536  numba          1,000     0.012     0.001     0.011     0.011     0.011     0.012     0.029     2.523
      65,536  numpy            100     0.030     0.001     0.028     0.029     0.029     0.030     0.037     1.000

     262,144  jax              100     0.041     0.002     0.038     0.040     0.041     0.042     0.052     2.779
     262,144  numba            100     0.044     0.003     0.037     0.042     0.043     0.045     0.055     2.618
     262,144  numpy            100     0.114     0.004     0.107     0.112     0.113     0.116     0.126     1.000

   1,048,576  numba            100     0.165     0.007     0.157     0.161     0.163     0.167     0.215     2.989
   1,048,576  jax              100     0.240     0.006     0.225     0.237     0.239     0.243     0.257     2.054
   1,048,576  numpy             10     0.493     0.008     0.479     0.489     0.492     0.494     0.513     1.000

   4,194,304  numba             10     0.667     0.014     0.647     0.656     0.665     0.682     0.685     3.165
   4,194,304  jax               10     1.135     0.009     1.117     1.129     1.135     1.143     1.149     1.861
   4,194,304  numpy             10     2.111     0.021     2.088     2.097     2.106     2.114     2.164     1.000

(time in wall seconds, less is better)
```

### GPU

```bash
$ CUDA_VISIBLE_DEVICES="0" python run.py benchmarks/turbulent_kinetic_energy/ --device gpu -b jax -b numpy

Estimating repetitions...
Running 33432 benchmarks...  [####################################]  100%          

benchmarks.turbulent_kinetic_energy
===================================
Running on GPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  jax           10,000     0.002     0.000     0.002     0.002     0.002     0.003     0.008     1.145
       4,096  numpy         10,000     0.003     0.000     0.002     0.002     0.003     0.003     0.009     1.000

      16,384  jax           10,000     0.003     0.000     0.002     0.002     0.003     0.003     0.010     3.279
      16,384  numpy          1,000     0.009     0.001     0.008     0.009     0.009     0.009     0.014     1.000

      65,536  jax            1,000     0.005     0.001     0.004     0.004     0.004     0.005     0.007     9.073
      65,536  numpy            100     0.042     0.003     0.036     0.041     0.042     0.043     0.051     1.000

     262,144  jax            1,000     0.013     0.001     0.011     0.012     0.013     0.014     0.016    10.767
     262,144  numpy            100     0.140     0.006     0.127     0.136     0.140     0.145     0.166     1.000

   1,048,576  jax              100     0.047     0.004     0.044     0.045     0.046     0.049     0.058    13.291
   1,048,576  numpy             10     0.630     0.021     0.590     0.613     0.638     0.645     0.657     1.000

   4,194,304  jax              100     0.178     0.014     0.164     0.166     0.173     0.193     0.207    13.956
   4,194,304  numpy             10     2.490     0.051     2.399     2.463     2.503     2.535     2.544     1.000

(time in wall seconds, less is better)
```

### TPU

```bash
$ JAX_BACKEND_TARGET="grpc://$COLAB_TPU_ADDR" python run.py benchmarks/turbulent_kinetic_energy -b jax -b numpy --device tpu

benchmarks.turbulent_kinetic_energy
===================================
Running on TPU

size          backend     calls     mean      stdev     min       25%       median    75%       max       Δ       
------------------------------------------------------------------------------------------------------------------
       4,096  jax           10,000     0.004     0.002     0.002     0.003     0.003     0.004     0.020     1.425
       4,096  numpy         10,000     0.005     0.001     0.003     0.004     0.005     0.006     0.018     1.000

      16,384  jax           10,000     0.004     0.002     0.002     0.003     0.003     0.004     0.028     3.843
      16,384  numpy          1,000     0.015     0.003     0.010     0.013     0.015     0.016     0.032     1.000

      65,536  jax           10,000     0.005     0.002     0.003     0.004     0.004     0.005     0.027    13.077
      65,536  numpy            100     0.060     0.009     0.044     0.057     0.060     0.066     0.082     1.000

     262,144  jax            1,000     0.010     0.003     0.004     0.008     0.011     0.012     0.026    19.048
     262,144  numpy            100     0.198     0.028     0.157     0.170     0.203     0.214     0.280     1.000

   1,048,576  jax            1,000     0.076     0.007     0.056     0.070     0.075     0.080     0.110    10.219
   1,048,576  numpy             10     0.772     0.083     0.673     0.684     0.788     0.850     0.871     1.000

   4,194,304  jax            1,000     0.339     0.027     0.288     0.317     0.340     0.361     0.403     7.577
   4,194,304  numpy             10     2.569     0.244     2.373     2.408     2.439     2.621     3.035     1.000

(time in wall seconds, less is better)
```
